# Ensembling-and-regularization

# Задание
Основные цели этого задания:

Научиться работать с новыми моделями: случайный лес, градиентный бустинг.

Научиться распознавать факты переобучения и недообучения модели.

Научить бороться с переобучением и недообучением модели путем варьирования ее гиперпараметров.

Задача:

Построить модель машинного обучения, предсказывающую, является ли вино красным по одиннадцати его характеристикам.

План решения:

Загрузите данные, объедините источники в один датафрейм. Составьте целевую переменную на основе файла, из которого вы получили часть данных (бинарный признак, принимающий значение 1 для данных из файла про красное вино и 0 для данных из файла про белое вино), изучите распределение по ней. Проверьте отсутствие пропусков в данных, отделите фичи и целевой признак друг от друга, разделите данные на обучающую и валидационную части.

Поскольку выборка несбалансирована, воспользуемся для оценки качества модели новой метрикой balanced_accuracy_score. Изучите формулу расчета метрики в документации и реализуйте функцию balanced_accuracy_score_my для ее расчета. На вход она должна принимать правильные и прогнозные метки классов, а возвращать число от 0 до 1. Убедитесь, что вы корректно реализовали расчет, сравнив значения, получаемые библиотечной реализацией и собственной, подавая на вход векторы:
y_true = [0, 1, 1, 1, 1, 1, 1, 0, 1]
y_pred = [1, 0, 1, 1, 1, 1, 0, 0, 1]

Подберите лучшую модель решающего дерева:

Переберите несколько значений какого-либо гиперпараметра, отвечающего за сложность дерева, для каждого значения оцените качество на обучающей и валидационной частях

Визуализируйте зависимость качества модели от значения гиперпараметров. Опишите зоны недообучения и переобучения, если вы их наблюдаете.

Выведите значение гиперпараметра, при котором качество модели на валидационной части наилучшее (не забудьте вывести и саму метрику).

Подберите лучшую модель случайного леса:

Переберите несколько значений какого-либо гиперпараметра дерева и для каждого из них — несколько значений гиперпараметра, отвечающего за количество решающих деревьев в случайном лесу. Для каждой комбинации гиперпараметров оцените качество на валидационной части.

Визуализируйте зависимость качества модели от значений гиперпараметров с помощью функции imshow. Опишите особенности, которые вы наблюдаете.

Выведите значения гиперпараметров, при которых качество модели на валидационной части выборки наилучшее.

Подберите лучший вариант градиентного бустинга:

Выделите из обучающей части данных часть для валидации градиентного бустинга в ходе обучения.

Зафиксируйте небольшое количество деревьев, значение какого-либо параметра, отвечающего за сложность решающих деревьев и значение величины шага градиентного бустинга. Обучите градиентный бустинг с выбранными параметрами, выводя в процессе обучения значение функции потерь на обучающей и валидационной частях. Выведите значение метрики качества на экран.

На фиксированном небольшом количестве деревьев сравните 3-4 комбинации значений параметров величины шага градиентного бустинга и какого-либо параметра, отвечающего за сложность решающих деревьев.

Выберите из рассмотренных комбинаций лучшую по метрике balanced_accuracy_score и обоснуйте свой выбор.

Увеличьте количество деревьев и опишите эффект. Изучите значение гиперпараметра early_stopping_rounds и воспользуйтесь им, чтобы сэкономить время, войдя в переобучение модели.

В выводах напишите, какая модель показала себя лучше всего, какого качества удалось достичь.
